{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data of consumers\n",
    "\n",
    "This notebook aims at loading and analyzing measurement data of Italian consumers, whose data are provided by the standard export format from e-Distribuzione.\n",
    "\n",
    "The data shall be all stored in a parent folder that contains subfolders, one for each consumers.\n",
    "Each subfolder shall start with an unique identified that defines the POD. For example:\n",
    "```\n",
    "parent_folder/IT000001_Name1_Surname1/...\n",
    "parent_folder/IT000002_Name2_Surname2/...\n",
    "```\n",
    "Each subfolder shall contain multiple xlsx files named \"ExportData_*.xlsx\" that contain the measurement data of the consumer.\n",
    "The notebook loads all of them and creates a single dataframe that contains all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup parameters and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"C:\\\\Users\\\\Davide\\\\Downloads\\\\Antrodoco\\\\Dati\"  # Folder containing the data\n",
    "START_POD = \"IT\"  # Identifier of the POD name\n",
    "output_merged = \"all_data.csv\"  # Output file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all data in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import major libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Dates, Plots, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    read_data(fp)\n",
    "\n",
    "Reads the data from the file with path 'fp' and return a DataFrame\n",
    "- rows are the days\n",
    "- columns are the quarters of each day\n",
    "\"\"\"\n",
    "function read_data(fp)\n",
    "    df_temp = CSV.read(\n",
    "        fp,\n",
    "        DataFrame;\n",
    "        delim=\";\",\n",
    "        header=false,\n",
    "        skipto=2,\n",
    "    )[:, 1:97]\n",
    "    rename!(df_temp, [\"Day\"; [\"$i\" for i = 1:96]])\n",
    "    # convert date string to date\n",
    "    df_temp[!, 1] = Date.(df_temp[!, 1], \"dd/mm/yyyy\")\n",
    "    # convert strings to float\n",
    "    df_temp[!, 2:end] = parse.(Float64, replace.(df_temp[!, 2:end], \",\" => \".\"))\n",
    "    return df_temp\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    time_from_index(q::Int)::Dates.Time\n",
    "\n",
    "Convert a quarter 'q' to a time.\n",
    "\"\"\"\n",
    "function time_from_index(q::Int)::Dates.Time\n",
    "    h = floor(Int, (q-1)/4)\n",
    "    m = 15*((q-1)%4)\n",
    "    return Dates.Time(h, m, 0)\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "standardize_data(df, name)\n",
    "\n",
    "Standardize the data in the DataFrame 'df' and return a DataFrame with the following columns:\n",
    "- pod_name: the name of the user\n",
    "- datetime: datetime of the measurement\n",
    "- value: the value of the measurement\n",
    "\"\"\"\n",
    "function standardize_data(df, pod_name)\n",
    "    df_stacked = stack(df, 2:97)\n",
    "    df_stacked[!, :variable] = parse.(Int, df_stacked[!, :variable])\n",
    "    df_stacked[!, :time] = time_from_index.(df_stacked[!, :variable])\n",
    "    df_stacked[!, :datetime] = DateTime.(df_stacked[!, :Day] .+ df_stacked[!, :time])\n",
    "    df_stacked[!, :name] .= pod_name\n",
    "    return df_stacked[!, [:name, :datetime, :value]]\n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "    get_POD_name(fp)\n",
    "\n",
    "Extract the name of the POD from the file path 'fp'.\n",
    "Assumptions: the name of the POD starts with \"IT\" and no other file or directory starts with \"IT\".\n",
    "\"\"\"\n",
    "function get_POD_name(fp, START_POD=START_POD)\n",
    "    dirname = split(fp, \"\\\\$START_POD\")[2]\n",
    "    POD_code = split(dirname, \"_\")[1]\n",
    "    return \"IT$POD_code\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_quarter = []\n",
    "\n",
    "for (root, dirs, files) in walkdir(data_folder)\n",
    "    for file in files\n",
    "        if endswith(file, \".csv\")\n",
    "            if startswith(file, \"ExportData_\")\n",
    "                fp = joinpath(root, file)  # get the full path of the file\n",
    "                println(fp)\n",
    "                pod_name = get_POD_name(fp)  # get the name of the POD\n",
    "                df = read_data(fp)  # read the data\n",
    "                df_st = standardize_data(df, pod_name)  # standardize the data\n",
    "                push!(df_list_quarter, df_st)  # append the DataFrame to the list\n",
    "            else\n",
    "                println(\"Skipping $file : not supported\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "df_all_data_raw = vcat(df_list_quarter...)\n",
    "\n",
    "# drop duplicates\n",
    "grp = groupby(df_all_data_raw, [:name, :datetime])\n",
    "df_all_data = combine(grp, :value => first => :value)\n",
    "\n",
    "# add auxiliary columns\n",
    "df_all_data[!, :hour] = Dates.hour.(df_all_data[!, :datetime])\n",
    "df_all_data[!, :quarter] = Dates.quarter.(df_all_data[!, :datetime])\n",
    "df_all_data[!, :month] = Dates.month.(df_all_data[!, :datetime])\n",
    "\n",
    "# sort values\n",
    "sort!(df_all_data, [:name, :datetime])\n",
    "\n",
    "# write to file\n",
    "CSV.write(output_merged, df_all_data, writeheader=true)\n",
    "\n",
    "first(df_all_data, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create simple statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some relevant statistics\n",
    "grp = groupby(df_all_data, :name)\n",
    "stats_by_POD = combine(\n",
    "    grp,\n",
    "    :datetime => (x->Date(minimum(x))) => :start,\n",
    "    :datetime => (x->Date(maximum(x))) => :end,\n",
    "    :datetime => (x->convert(Dates.Day, Date(maximum(x))-Date(minimum(x))) + Day(1)) => :delta_extremes,\n",
    "    :datetime => (x->length(unique(Date.(x)))) => :n_days,\n",
    "    :value => (x->sum(x)/1000) => :sum_values,\n",
    ")\n",
    "stats_by_POD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an average hourly plot by consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = groupby(df_all_data, [:name, :hour])\n",
    "stats_hourly = combine(\n",
    "    grp,\n",
    "    :value => (x->4*mean(x)) => :avg_value,\n",
    "    :value => (x->4*std(x)) => :std_value,\n",
    ")\n",
    "stats_hourly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe with the average hourly consumption of each consumer:\n",
    "- columns represent different consumers\n",
    "- rows represent different hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate average values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_by_POD = unstack(stats_hourly[!, Not(:std_value)], :name, :avg_value)\n",
    "sort!(avg_by_POD, :hour)  # sort by hour\n",
    "avg_by_POD = avg_by_POD[!, Not(:hour)]  # drop the hour column\n",
    "avg_by_POD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the plot of the average hourly consumption by consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot()\n",
    "for col in names(avg_by_POD)\n",
    "    plot!(x, avg_by_POD[!, col], label=col, legend=:right)\n",
    "end\n",
    "xlabel!(\"Hour (h)\")\n",
    "ylabel!(\"Average consumption (kW)\")\n",
    "display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylims!((0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_by_POD = unstack(stats_hourly[!, Not(:avg_value)], :name, :std_value)\n",
    "sort!(std_by_POD, :hour)  # sort by hour\n",
    "std_by_POD = std_by_POD[!, Not(:hour)]  # drop the hour column\n",
    "std_by_POD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plot()\n",
    "for col in names(avg_by_POD)\n",
    "    plot!(x, avg_by_POD[!, col], yerr=std_by_POD[!, col], label=col, legend=:right)\n",
    "end\n",
    "xlabel!(\"Hour (h)\")\n",
    "ylabel!(\"Average consumption (kW)\")\n",
    "display(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
